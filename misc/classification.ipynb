{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dbd8bf-dc41-4103-867a-718188d2d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6d8f0-4799-444d-afe0-6aec6d0d91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00798552-10c5-4cb1-9357-e4561760c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"popularity\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248d2d3-c0a3-4de5-aced-18057ee8e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['popularity'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4730d-694c-4858-8221-dc77a26b3847",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = so.Plot(df, \"popularity\")\n",
    "p.add(so.Bars(), so.Hist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b67bfa-7606-4b26-9f41-c565df37bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping any song where \"popularity\" = 0 as it's likely 0 is just a placeholder for missing values\n",
    "df.drop(df[df[\"popularity\"] == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18daea10-fdd8-44fd-90a2-aac59aba85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check - this should equal 0\n",
    "df.loc[df[\"popularity\"] ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c393e5-b257-4cfe-b294-9652d06e4df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = so.Plot(df, \"popularity\")\n",
    "p.add(so.Bars(), so.Hist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb6ca9-44f4-4322-b613-cdb83fc41252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c5414-a3fd-4bd6-838c-22efa6944358",
   "metadata": {},
   "outputs": [],
   "source": [
    "^^ There's clearly some class imbalance here ... I think we need to SMOTE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589957a-a7a0-4dc8-b7cd-bf270f6a02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "to_drop = ['popularity', 'id', 'artists', 'name', 'release_date', 'year', 'target']\n",
    "\n",
    "X = df.drop(labels= to_drop, axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=27)\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31367282-09ba-4d3e-a395-924033082db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5b2d0-9003-4dde-8dd3-a69366c8883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e5b4a6-eefc-4218-82b9-f11d183ff60e",
   "metadata": {},
   "source": [
    "# Baseline Model - might delete this since we didn't do any preprocessing, it feels a little irrelevant\n",
    "let's just do a dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da651ccf-48c0-4943-83f1-7cbe75691d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "# Instantiate the model\n",
    "dummy_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# fitting the model to our newly encoded dataset\n",
    "dummy_model.fit(X_train, y_train)\n",
    "\n",
    "# predicting the first 10\n",
    "dummy_model.predict(X_test)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcba6cd-36b0-48cc-8551-997aebc5bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the ratio of 1 to 0 in our training set\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea5a5f-ce8d-4611-9c9b-89afc5ee2390",
   "metadata": {},
   "source": [
    "This tracks that the dummy classifier gave us zeroes as our train and test have basically the same ratio of 0 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f33b3-2c7a-4f6d-b98b-466dbf3b56ad",
   "metadata": {},
   "source": [
    "# First model - no SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111a863-0975-40df-9cf4-feefd55881e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "numeric_features = ['valence', 'acousticness','energy', 'danceability', 'duration_ms', 'explicit', 'instrumentalness', \n",
    "              'liveness', 'loudness', 'mode', 'speechiness', 'tempo']\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "categorical_features = ['key']\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "\n",
    "CT = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Logistic Regression Pipeline with SMOTE and GridSearchCV\n",
    "pipe_lr = ImPipeline(steps=[\n",
    "    ('preprocessor', CT),\n",
    "    ('classifier', LogisticRegression(random_state=0, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01482b59-b62c-4e38-ad56-abe02fc14bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "#  predictions\n",
    "y_predict_lr = pipe_lr.predict(X_test)\n",
    "y_predict_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e3600-1509-4788-8284-2ec2628022d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a confusion matrix to assess our model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_predict_lr)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ea0c4-eec9-4f30-84ab-f0b0d9e512af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Our model's accuracy on the test set is {round(accuracy_score(y_test, y_predict_lr), 2)}.\n",
    "Our model's recall on the test set is {round(recall_score(y_test, y_predict_lr), 2)}.\n",
    "Our model's precision on the test set is {round(precision_score(y_test, y_predict_lr), 2)}.\n",
    "Our model's f1-score on the test is {round(f1_score(y_test, y_predict_lr), 2)}.\n",
    "\"\"\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_predict_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86587dd6-61e2-4c76-b92d-169bee43fd23",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "\n",
    "The evaluation metric that I think makes the most sense is precision. If we have a false positive (a song is listed as popular but it is not) there is a higher probability the listener will skip the song if they don't like it. If we have a false negative (a song is not listed as popular but it is) it will likely not be recommended to the listener and will hence not be heard. For business purposes, it makes the most sense to maximize listening time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab54ac7-ba1e-4dc5-b191-2c3b96419bc4",
   "metadata": {},
   "source": [
    "# Now let's try with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7551a-4f3f-4707-8ddf-4b084edba6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Logistic Regression Pipeline with SMOTE and GridSearchCV\n",
    "pipe_smote_lr = ImPipeline(steps=[\n",
    "    ('preprocessor', CT),\n",
    "    ('smote', SMOTE(random_state=27)),\n",
    "    ('classifier', LogisticRegression(random_state=0, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "pipe_smote_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a874c9-cbd6-42a9-8004-c5f1d4b26021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the trained logistic regression classifier from the pipeline\n",
    "lr_model = pipe_smote_dt.named_steps['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d0d95-2371-4194-bcea-171e9e6f5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_predict_smote_lr = lr_model.predict(X_test)\n",
    "y_predict_smote_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021daef-8424-4656-b7d0-685f6afa7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a confusion matrix to assess our model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_predict_smote_lr)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db35c6-868d-49e1-8e68-caab176358e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Our model's accuracy on the test set is {round(accuracy_score(y_test, y_predict_smote_lr), 2)}.\n",
    "Our model's recall on the test set is {round(recall_score(y_test, y_predict_smote_lr), 2)}.\n",
    "Our model's precision on the test set is {round(precision_score(y_test, y_predict_smote_lr), 2)}.\n",
    "Our model's f1-score on the test is {round(f1_score(y_test, y_predict_smote_lr), 2)}.\n",
    "\"\"\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_predict_smote_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b57461-b693-4b0d-9833-580a9b8f597b",
   "metadata": {},
   "source": [
    "It looks like there is minimal difference with SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96180343-9092-4a53-becd-4f86a0ad2735",
   "metadata": {},
   "source": [
    "# Decision Tree for Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a16017-83c1-40cd-ba38-a228a5a845c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# Define the pipeline\n",
    "pipe_smote_dt = ImPipeline(steps=[\n",
    "    ('preprocessor', CT),\n",
    "    ('smote', SMOTE(random_state=27)),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=3, random_state=27))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipe_smote_dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_dt = pipe_smote_dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"\"\"\n",
    "Our model's accuracy on the test set is {round(accuracy_score(y_test, y_pred_dt), 2)}.\n",
    "Our model's recall on the test set is {round(recall_score(y_test, y_pred_dt), 2)}.\n",
    "Our model's precision on the test set is {round(precision_score(y_test, y_pred_dt), 2)}.\n",
    "Our model's f1-score on the test is {round(f1_score(y_test, y_pred_dt), 2)}.\n",
    "\"\"\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Extract the trained decision tree classifier from the pipeline\n",
    "dt_model = pipe_smote_dt.named_steps['dt']\n",
    "\n",
    "# Plotting the decision tree\n",
    "plt.figure(figsize=(20, 15))  # Set plot size (denoted in inches)\n",
    "plot_tree(dt_model, filled=True, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9bf896-f4bf-4a72-8552-e66e61af47f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ab4c2-8426-4fa3-ba58-7376009b76d1",
   "metadata": {},
   "source": [
    "# The features that the decision tree split on are key, energy, danceability, and duration. Let's try running a model with just those columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fec52b8-ccc4-4c0e-855c-f2e4f050d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# singling out those 4 columns\n",
    "X_train_small = X_train[['energy', 'key', 'danceability', 'duration_ms']]\n",
    "X_train_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f27cfc-a935-4e58-9d12-132eec80dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.loc[X_train_small[\"key\"] == 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d66e0-9bcb-4322-9dd2-e7a1bf43e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60f986-2d3c-4421-9c73-28675fd3f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to define a new pipeline since the orinigal column transformer was trained on the full X_train set\n",
    "\n",
    "numeric_small = ['energy', 'danceability', 'duration_ms']\n",
    "categorical_small = ['key']\n",
    "\n",
    "ss_nn = StandardScaler()\n",
    "ohe_nn = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "numeric_transformed = ss_nn.fit_transform(X_train_small[numeric_small])\n",
    "cat_transformed = ohe_nn.fit_transform(X_train_small[categorical_small])\n",
    "\n",
    "print(\"Numeric Transformed Shape:\", numeric_transformed.shape)\n",
    "print(\"Categorical Transformed Shape:\", cat_transformed.shape)\n",
    "\n",
    "# Convert the sparse matrix to a dense numpy array\n",
    "cat_transformed_dense = cat_transformed.toarray()\n",
    "\n",
    "# Concatenate the transformed numeric and categorical features\n",
    "X_train_small_processed = np.concatenate([numeric_transformed, cat_transformed_dense], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b65c9f-aae5-4772-83d9-0c782070c39f",
   "metadata": {},
   "source": [
    "# this isn't working. I'll look at it later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6695ca3-1952-43d9-85ac-7059c2f32585",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model = LogisticRegression()\n",
    "\n",
    "small_model.fit(X_train_small_processed, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_small = small_model.predict(X_test)\n",
    "print(y_pred_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72902262-fd4d-49fc-956c-8ffee077d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict_smote_lr)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e531ad5-6b34-4c4d-a724-19ff13f11f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Our model's accuracy on the test set is {round(accuracy_score(y_test, y_predict_smote_lr), 2)}.\n",
    "Our model's recall on the test set is {round(recall_score(y_test, y_predict_smote_lr), 2)}.\n",
    "Our model's precision on the test set is {round(precision_score(y_test, y_predict_smote_lr), 2)}.\n",
    "Our model's f1-score on the test is {round(f1_score(y_test, y_predict_smote_lr), 2)}.\n",
    "\"\"\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_predict_smote_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb113e9c-008c-4bfb-8e20-3c2017740b10",
   "metadata": {},
   "source": [
    "## Grid Search? might get rid of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b6c389-0ce3-49f8-8d43-9b927b5eb8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 100% of the training data for initial tuning\n",
    "# Create a random sample of 100 rows\n",
    "X_train_sample = X_train.sample(n=100, random_state=27)\n",
    "y_train_sample = y_train.sample(n=100, random_state=27)\n",
    "\n",
    "# Split the sampled data into small training and testing sets\n",
    "small_X_train, small_X_test, small_y_train, small_y_test = train_test_split(\n",
    "    X_train_sample, y_train_sample, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a6ce2-f356-4ba6-9e6a-5a7fad131b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try a gridsearch with cross validation\n",
    "parameters = {'rfc__criterion': ['gini', 'entropy'],\n",
    "          'rfc__max_depth': [3, 5],\n",
    "          'smote__k_neighbors': [3, 5, 9]}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_smote_rf,\n",
    "                 param_grid=parameters,\n",
    "                 cv=5)\n",
    "\n",
    "# fit to samples to minimize run time\n",
    "#gs.fit(small_X_train, small_y_train)\n",
    "\n",
    "print(#gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f8855-ad0b-4ad0-86d8-2dcd80a3d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_parameters = {'rfc__criterion': ['gini', 'entropy'],\n",
    "          'rfc__max_depth': [10, 20],\n",
    "          'smote__k_neighbors': [3, 5, 9]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
